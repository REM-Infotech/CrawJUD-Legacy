# =========================
# Celery Configuration (YAML plano)
# =========================
# Convenção Celery 5+: chaves em minúsculas.
# Broker/Backend: RabbitMQ (broker) + RPC (backend)
# Timezone: America/Sao_Paulo
# Concurrency: 8 fixo

# =========================
# General settings
# =========================
broker_url: "amqp://guest:guest@localhost:5672//" # URL do RabbitMQ (broker principal)
broker_read_url: null # Opcional: URL separada para consumo
broker_write_url: null # Opcional: URL separada para produção
accept_content: ["json"] # White-list de formatos aceitos
result_accept_content: null # Padrão = accept_content (se null)
enable_utc: true # Converter datas/horas para UTC internamente
timezone: "America/Sao_Paulo" # Fuso preferido para agendamentos (beat)
task_serializer: "json" # Serializador padrão para tasks
result_serializer: "json" # Serializador padrão para resultados
task_protocol: 2 # Protocolo de mensagem (1 ou 2)
task_compression: null # gzip, bzip2, ou null (sem compressão)
result_compression: null # Compressão do resultado (opcional)
task_annotations: null # Ex: {'*': {'rate_limit': '10/s'}}
imports: [] # Módulos importados no start do worker
include: [] # Módulos adicionais (importados após 'imports')

# =========================
# Message Sending Retry
# =========================
task_publish_retry: true # Re-tentar publicar tasks ao perder conexão
task_publish_retry_policy: null # Política detalhada (usa defaults se null)

# =========================
# Task settings
# =========================
task_always_eager: false # Executa localmente (modo síncrono) — DEV
task_eager_propagates: false # Propaga exceptions em modo eager
task_store_eager_result: false # Salva resultado em modo eager (se ignore_result=False)
task_remote_tracebacks: false # Inclui traceback remoto em erros (requer tblib)
task_ignore_result: false # Não armazenar resultados de sucesso
task_store_errors_even_if_ignored: false # Armazenar erros mesmo se ignore_result=True
task_track_started: false # Relatar estado "STARTED"
task_time_limit: null # Hard time limit (segundos)
task_soft_time_limit: null # Soft time limit (segundos)
task_default_rate_limit: null # Rate global (ex: "10/s")
task_default_priority: null # Prioridade default (Rabbit/Redis)
task_default_queue: "celery" # Fila default
task_default_exchange: "celery" # Exchange default
task_default_exchange_type: "direct" # Tipo da exchange default
task_default_routing_key: "celery" # Routing key default
task_acks_late: false # Ack após execução (cuidado com idempotência)
task_acks_on_failure_or_timeout: true # Ack mesmo em falha/timeout (se acks_late)
task_reject_on_worker_lost: false # Re-enfileira se worker "sumir" (pode causar loops)
task_send_sent_event: false # Emite evento "task-sent"
task_allow_error_cb_on_chord_header: false # Linkar error callbacks ao header de chords

# =========================
# Task execution (canvas / chords / joins)
# =========================
result_backend: "rpc://" # Backend de resultados via RabbitMQ (RPC)
result_backend_always_retry: false # Retry no backend em exceções recuperáveis
result_backend_max_sleep_between_retries_ms: 10000 # Sleep máximo entre retries (ms)
result_backend_base_sleep_between_retries_ms: 10 # Sleep base entre retries (ms)
result_backend_max_retries: null # Máx. de retries (null = infinito)
result_backend_thread_safe: false # Compartilhar backend entre threads
result_backend_transport_options: {} # Opções extras p/ transport do backend
result_extended: false # Armazenar metadados estendidos
result_expires: 86400 # Expiração de resultados (segundos) — 1 dia
result_cache_max: null # Cache local de resultados (desativado por padrão)
result_chord_join_timeout: 3.0 # Timeout ao fazer join de chord (segundos)
result_chord_retry_interval: 1.0 # Intervalo de retry de chord (segundos)
override_backends: null # Mapear backend customizado (ex: {"db": "mod.Class"})

# =========================
# Routing & Queues
# =========================
task_queues: null # Lista de kombu.Queue (geralmente omitido)
task_routes: null # Rotas (dict, lista de tuplas ou função)
worker_direct: false # Fila dedicada por worker (C.dq2)
task_create_missing_queues: true # Criar filas não definidas automaticamente
task_create_missing_queue_type: "classic" # Tipo da fila criada automaticamente (RabbitMQ)
task_create_missing_queue_exchange_type: null # Tipo de exchange para filas auto-criadas
task_queue_max_priority: null # Prioridade máxima (RabbitMQ)
task_inherit_parent_priority: false # Herdar prioridade do "pai"

# =========================
# Broker (RabbitMQ)
# =========================
broker_failover_strategy: "round-robin" # Estratégia de failover entre URLs
broker_heartbeat: 120.0 # Heartbeat AMQP (negociado pelo servidor)
broker_heartbeat_checkrate: 2.0 # Frequência de checagem do heartbeat
broker_use_ssl: false # SSL para broker (bool ou dict de opções)
broker_pool_limit: 10 # Máximo de conexões no pool do broker
broker_connection_timeout: 4.0 # Timeout p/ conectar ao broker
broker_connection_retry: true # Retry após perder conexão (pós-inicialização)
broker_connection_retry_on_startup: true # Retry também na inicialização
broker_connection_max_retries: 100 # Máximo de tentativas de reconexão
broker_channel_error_retry: false # Retry ao receber resposta AMQP inválida
broker_login_method: "AMQPLAIN" # Método de login AMQP
broker_native_delayed_delivery_queue_type: "quorum" # Tipo para filas nativas "delayed"
broker_transport_options: {} # Ex: {"confirm_publish": True, "max_retries": 5}

# =========================
# Worker settings
# =========================
worker_concurrency: 8 # Número fixo de processos/threads por worker
worker_prefetch_multiplier: 4 # Prefetch = concurrency * multiplier
worker_eta_task_limit: null # Máx. de tasks com ETA em memória
worker_disable_prefetch: false # (Redis) desabilitar prefetch, consumir sob demanda
worker_enable_prefetch_count_reduction: true # Ajusta prefetch após reconexões
worker_lost_wait: 10.0 # Espera por resultados atrasados antes de WorkerLostError
worker_max_tasks_per_child: null # Reciclar processos após N tasks (None = ilimitado)
worker_max_memory_per_child: null # Reciclar processo após X KB de RSS
worker_disable_rate_limits: false # Desativar todos rate limits
worker_state_db: null # Arquivo de estado persistente do worker
worker_timer_precision: 1.0 # Precisão (s) do agendador ETA
worker_enable_remote_control: true # Habilita comandos remotos (celery control)
worker_proc_alive_timeout: 4.0 # Timeout p/ aguardar processo de worker iniciar
worker_cancel_long_running_tasks_on_connection_loss: false # Cancelar tasks longas em perda de conexão
worker_detect_quorum_queues: true # Detectar filas quorum e ajustar QoS
worker_soft_shutdown_timeout: 0.0 # Espera antes de shutdown "frio"
worker_enable_soft_shutdown_on_idle: false # Aplicar soft shutdown mesmo sem tasks
worker_hijack_root_logger: true # Worker assume o root logger
worker_log_color: null # Habilita/desabilita color no log (auto)
worker_log_format: "[%(asctime)s: %(levelname)s/%(processName)s] %(message)s"
worker_task_log_format: "[%(asctime)s: %(levelname)s/%(processName)s] %(task_name)s[%(task_id)s]: %(message)s"
worker_redirect_stdouts: true # Redireciona stdout/err para logger
worker_redirect_stdouts_level: "WARNING" # Nível para stdout/stderr
worker_deduplicate_successful_tasks: false # Deduplicação local de tasks "SUCCESS"
worker_pool: "prefork" # Pool (prefork padrão)
worker_pool_restarts: false # Permitir restart do pool por comando remoto
worker_autoscaler: "celery.worker.autoscale:Autoscaler" # Classe de autoscaler
worker_consumer: "celery.worker.consumer:Consumer" # Classe de consumer
worker_timer: "kombu.asynchronous.hub.timer:Timer" # Classe do agendador ETA
worker_logfile: null # Caminho do arquivo de log do worker
worker_pidfile: null # Caminho do PID file do worker
worker_uid: null # UID para drop privileges
worker_gid: null # GID para drop privileges
worker_umask: null # Umask ao daemonizar
worker_executable: null # Python executable ao daemonizar

# =========================
# Beat (celery beat) — Agendador
# =========================
beat_schedule: {} # Tarefas periódicas
beat_scheduler: "celery.beat:PersistentScheduler" # Scheduler padrão
beat_schedule_filename: "celerybeat-schedule" # Arquivo do scheduler
beat_sync_every: 0 # 0 = sync baseado em tempo; 1 = a cada task
beat_max_loop_interval: 0 # Default depende do scheduler (Persistent=300s)
beat_cron_starting_deadline: null # Janela p/ rodar cron atrasado
beat_logfile: null # Caminho de log do beat
beat_pidfile: null # PID file do beat
beat_uid: null # UID (drop privileges)
beat_gid: null # GID (drop privileges)
beat_umask: null # Umask ao daemonizar
beat_executable: null # Python executable ao daemonizar

# =========================
# Events (monitoramento)
# =========================
worker_send_task_events: false # Enviar eventos de tasks (necessário p/ Flower)
event_queue_ttl: 5.0 # TTL da fila de eventos (amqp)
event_queue_expires: 60.0 # Expiração da fila de eventos (amqp)
event_queue_durable: false # Fila de eventos durável
event_queue_exclusive: false # Fila de eventos exclusiva
event_queue_prefix: "celeryev" # Prefixo do nome da fila de eventos
event_exchange: "celeryev" # Exchange de eventos
event_serializer: "json" # Serializador de eventos
events_logfile: null # Logfile do "celery events"
events_pidfile: null # PID file do "celery events"
events_uid: null # UID ao daemonizar "celery events"
events_gid: null # GID ao daemonizar "celery events"
events_umask: null # Umask
events_executable: null # Python executable

# =========================
# Remote Control Commands
# =========================
control_queue_ttl: 300.0 # TTL das mensagens de controle
control_queue_expires: 10.0 # Expiração da fila de controle inativa
control_exchange: "celery" # Exchange de controle
control_queue_durable: false # Fila de controle durável
control_queue_exclusive: false # Fila de controle exclusiva

# =========================
# Logging (geral da app)
# =========================
# (Os parâmetros de worker_* acima já cobrem a maioria dos casos)
# Você pode ainda configurar logging via signals (setup_logging) se preferir.

# =========================
# Security (Assinatura de mensagens)
# =========================
security_key: null # Caminho da chave privada (assinatura)
security_key_password: null # Senha da chave privada
security_certificate: null # Cert X.509 (assinatura)
security_cert_store: null # Diretório de certificados
security_digest: "sha256" # Hash usado na assinatura

# Observação: você está usando backend "rpc://".
# Ainda assim, deixo opções de outros backends como null, para referência futura.

# =========================
# Redis backend (se trocar futuramente)
# =========================
redis_backend_health_check_interval: null # Segundos entre health-checks
redis_backend_use_ssl: null # Dict de SSL p/ backend Redis
redis_max_connections: null # Máx. conexões no pool Redis backend
redis_socket_connect_timeout: null # Timeout conexão (s)
redis_socket_timeout: 120.0 # Timeout read/write (s)
redis_retry_on_timeout: false # Re-tentar em TimeoutError
redis_socket_keepalive: false # TCP keepalive
redis_client_name: null # Nome do cliente (monitoramento)

# =========================
# Database backend (SQLAlchemy), se optar
# =========================
database_create_tables_at_setup: true # Criar tabelas no setup
database_engine_options: {} # Ex: {'echo': True}
database_short_lived_sessions: false # Conexões de curta duração (pode afetar perf)
database_table_schemas: {} # Schemas customizados
database_table_names: {} # Nomes de tabelas customizados

# =========================
# MongoDB backend
# =========================
mongodb_backend_settings: null # {database, taskmeta_collection, max_pool_size, options}

# =========================
# Cache backend (Memcached/in-memory)
# =========================
cache_backend_options: {} # Opções pylibmc (se usar)
cache_backend: null # (não usado em backends atuais) — doc legado

# =========================
# S3 backend
# =========================
s3_access_key_id: null
s3_secret_access_key: null
s3_bucket: null
s3_base_path: null
s3_endpoint_url: null
s3_region: null

# =========================
# Azure Block Blob backend
# =========================
azureblockblob_container_name: "celery"
azureblockblob_base_path: null
azureblockblob_retry_initial_backoff_sec: 2
azureblockblob_retry_increment_base: 2
azureblockblob_retry_max_attempts: 3
azureblockblob_connection_timeout: 20
azureblockblob_read_timeout: 120

# =========================
# GCS backend
# =========================
gcs_bucket: null
gcs_project: null
gcs_base_path: null
gcs_ttl: 0
gcs_threadpool_maxsize: 10
firestore_project: null

# =========================
# Elasticsearch backend
# =========================
elasticsearch_retry_on_timeout: false
elasticsearch_max_retries: 3
elasticsearch_timeout: 10.0
elasticsearch_save_meta_as_text: true

# =========================
# Cassandra / Astra DB backend
# =========================
cassandra_servers: [] # Lista de hosts Cassandra
cassandra_secure_bundle_path: null # Astra: caminho do secure-connect-bundle.zip
cassandra_port: 9042
cassandra_keyspace: null
cassandra_table: null
cassandra_read_consistency: null # ONE/TWO/THREE/QUORUM/ALL/...
cassandra_write_consistency: null
cassandra_entry_ttl: null
cassandra_auth_provider: null # PlainTextAuthProvider / SaslAuthProvider
cassandra_auth_kwargs: {} # {username, password}
cassandra_options: {} # protocol_version, execution_profiles, etc.

# =========================
# DynamoDB backend
# =========================
dynamodb_endpoint_url: null
# result_backend via URL (ex.: 'dynamodb://@us-east-1/celery_results') — configurar na chave result_backend

# =========================
# IronCache backend
# =========================
# result_backend via URL (ex.: 'ironcache://project_id:token@')
# ironcache usa URL; opções extras configuradas na própria URL.

# =========================
# Couchbase backend
# =========================
couchbase_backend_settings: {} # host, port, bucket, username, password

# =========================
# ArangoDB backend
# =========================
arangodb_backend_settings: {} # host, port, database, collection, username, password, http_protocol, verify

# =========================
# CosmosDB (experimental)
# =========================
cosmosdbsql_database_name: "celerydb"
cosmosdbsql_collection_name: "celerycol"
cosmosdbsql_consistency_level: "Session"
cosmosdbsql_max_retry_attempts: 9
cosmosdbsql_max_retry_wait_time: 30

# =========================
# Consul K/V backend
# =========================
# result_backend via URL (ex.: 'consul://localhost:8500/'); one_client via querystring

# =========================
# File-system backend
# =========================
# result_backend via URL (ex.: 'file:///var/celery/results')

# =========================
# Extra — prioridade/quorum defaults
# =========================
task_default_queue_type: "classic" # Tipo da fila default (RabbitMQ)
# worker_detect_quorum_queues: true                    # Já definido acima (duplicado aqui para referência)

# =========================
# Fim do arquivo
# =========================
